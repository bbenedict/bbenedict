### 100 days of AI/ML learning

A few years ago I did 100 days of learning. Each day I tried to learn 
one thing by reading, watching vidoes or coding projects.  It was one 
of the most rewarding projects I ever started.  It's time to do it again!

My focus this time will be exclusively on AI/ML.  I am again mid-course on
Coursera.  I also have a list of topics related to NLP and text processing.  

Wish me luck!
  
## day 1 (Nov 19, 2022)

Today I watched videos on Lowenshtein Edit Distance, The Wagner Fischer algorithm
for edit distance and Term Frequency - Inverse Document Frequency (TF-IDF).

Edit distance is the number of edits (change, add, delete) it takes to turn a word 
into another word. (https://www.youtube.com/watch?v=Cu7Tl7FGigQ&t=1124s)
The Wagner Fischer approach basically uses a matrix to avoid the redundant, recursive
approach of the original algorithm.

TF-IDF can be used to vectorize or analyze documents.  TF is the frequency of a word in a document
(word count / total words). IDF is the log of the total number of documents over the number of docuemnts 
that have the word ( log(total documents / documents with word) ). The final value is just TFxIDF.
(https://www.youtube.com/watch?v=D2V1okCEsiE&t=446s).  You can create a vectorized version of the
document from the TF-IDF of each word in your dictionary for the document.

## day 2 (Nov 20, 2022)

Continued on my Coursera NLP certification with Natural Language Processing with Probabilistic Models.
Using minimum edit distance in an applicable sense for auto-correct. Interesting that there was a slight
difference in the use of the cost of a replace operation.  The course also referred to the matrix approach
as a good example of Dynamic Programming.

## day 3 (Nov 21, 2022)

I did some perusing of Natural Languges Processing with Transformers and Practical Statistics for
Data Scientists both published by O'Reilly, causing me to wonder yet again why I don't just use their
subscription model.  I read through the QA chapter in the transformer book.  The example is very similar to 
what my current company does. Sometimes, this book focuses a little too much on logistical steps.  You could
just show us the data files and the shape of the data needed rather than take us through each programming step.
I used the stats book to brush up on bagging, trees and random forest for a project I am hoping to do for
this 100 days project.

## day 4 (Nov 22, 2022)

Back to Coursera NLP.  We covered Parts of Speech Tagging, Markov Chains and the Vertabi algorithm.  I will
definitely need the lab to better understand this week.






